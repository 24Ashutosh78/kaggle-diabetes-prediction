{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0c69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c5ed7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data \n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "TARGET = \"diagnosed_diabetes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e5f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[\"id\", TARGET])\n",
    "y = train[TARGET].astype(int)\n",
    "test_ids = test[\"id\"]\n",
    "X_test = test.drop(columns=[\"id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa7c5db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # All 30+ features from previous code (BP, lipids, lifestyle, etc.)\n",
    "    df[\"bmi_age_ratio\"] = df[\"bmi\"] / (df[\"age\"] + 1e-3)\n",
    "    df[\"activity_sleep_ratio\"] = df[\"physical_activity_minutes_per_week\"] / (df[\"sleep_hours_per_day\"] + 1)\n",
    "    df[\"bp_ratio\"] = df[\"systolic_bp\"] / (df[\"diastolic_bp\"] + 1)\n",
    "    df[\"lipid_ratio\"] = df[\"cholesterol_total\"] / (df[\"triglycerides\"] + 1)\n",
    "    df[\"pulse_pressure\"] = df[\"systolic_bp\"] - df[\"diastolic_bp\"]\n",
    "    df[\"mean_arterial_pressure\"] = df[\"diastolic_bp\"] + (df[\"systolic_bp\"] - df[\"diastolic_bp\"]) / 3.0\n",
    "    df[\"non_hdl_cholesterol\"] = df[\"cholesterol_total\"] - df[\"hdl_cholesterol\"]\n",
    "    df[\"ldl_hdl_ratio\"] = df[\"ldl_cholesterol\"] / (df[\"hdl_cholesterol\"] + 1e-3)\n",
    "    df[\"tg_hdl_ratio\"] = df[\"triglycerides\"] / (df[\"hdl_cholesterol\"] + 1e-3)\n",
    "    df[\"bmi_sq\"] = df[\"bmi\"] ** 2\n",
    "    df[\"log_bmi\"] = np.log1p(df[\"bmi\"])\n",
    "    df[\"bmi_waist_hip\"] = df[\"bmi\"] * df[\"waist_to_hip_ratio\"]\n",
    "    df[\"waist_hip_age\"] = df[\"waist_to_hip_ratio\"] * df[\"age\"]\n",
    "    df[\"sedentary_ratio\"] = df[\"screen_time_hours_per_day\"] / (df[\"sleep_hours_per_day\"] + 1)\n",
    "    df[\"activity_sedentary_ratio\"] = df[\"physical_activity_minutes_per_week\"] / (df[\"screen_time_hours_per_day\"] + 1)\n",
    "    df[\"low_sleep\"] = (df[\"sleep_hours_per_day\"] < 6).astype(int)\n",
    "    df[\"high_screen\"] = (df[\"screen_time_hours_per_day\"] > 6).astype(int)\n",
    "    df[\"low_activity\"] = (df[\"physical_activity_minutes_per_week\"] < 150).astype(int)\n",
    "    df[\"poor_diet\"] = (df[\"diet_score\"] < df[\"diet_score\"].quantile(0.3)).astype(int)\n",
    "    df[\"lifestyle_risk_score\"] = df[[\"low_sleep\", \"high_screen\", \"low_activity\", \"poor_diet\"]].sum(axis=1)\n",
    "    \n",
    "    history_cols = [\"family_history_diabetes\", \"hypertension_history\", \"cardiovascular_history\"]\n",
    "    for col in history_cols:\n",
    "        df[col + \"_bin\"] = (df[col] == \"Yes\").astype(int)\n",
    "    df[\"comorbid_count\"] = df[[col + \"_bin\" for col in history_cols]].sum(axis=1)\n",
    "    df[\"comorbid_age_interaction\"] = df[\"comorbid_count\"] * df[\"age\"]\n",
    "    \n",
    "    # Outlier clipping\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        lower, upper = df[col].quantile([0.01, 0.99])\n",
    "        df[col] = df[col].clip(lower, upper)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ee65ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = advanced_feature_engineering(X)\n",
    "X_test = advanced_feature_engineering(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c686e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features encoded: ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', 'employment_status']\n"
     ]
    }
   ],
   "source": [
    "# Label encode categoricals for XGBoost/LightGBM\n",
    "cat_features = X.select_dtypes(include=\"object\").columns.tolist()\n",
    "label_encoders = {}\n",
    "for col in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(\"Categorical features encoded:\", cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff231e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3-MODEL ENSEMBLE ===\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a11700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store OOF predictions for each model\n",
    "oof_cat = np.zeros(len(X))\n",
    "oof_xgb = np.zeros(len(X))\n",
    "oof_lgb = np.zeros(len(X))\n",
    "test_cat = np.zeros(len(X_test))\n",
    "test_xgb = np.zeros(len(X_test))\n",
    "test_lgb = np.zeros(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e68cc8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CATBOOST (3 seeds for diversity)\n",
    "cat_params = {\n",
    "    'iterations': 2000, 'learning_rate': 0.03, 'depth': 6,\n",
    "    'l2_leaf_reg': 5, 'subsample': 0.85, 'colsample_bylevel': 0.7,\n",
    "    'class_weights': [1, 1.2], 'random_seed': 42, 'verbose': False\n",
    "}\n",
    "\n",
    "for seed in [42, 123, 777]:\n",
    "    cat_params['random_seed'] = seed\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = CatBoostClassifier(**cat_params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_val, y_val), \n",
    "                 early_stopping_rounds=150, verbose=False)\n",
    "        \n",
    "        oof_cat[val_idx] += model.predict_proba(X_val)[:, 1] / (skf.n_splits * 3)\n",
    "        test_cat += model.predict_proba(X_test)[:, 1] / (skf.n_splits * 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f211c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost CV AUC: 0.7248220472106447\n"
     ]
    }
   ],
   "source": [
    "print(f\"CatBoost CV AUC: {roc_auc_score(y, oof_cat):}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d8d1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. XGBOOST (3 seeds)\n",
    "xgb_params = {\n",
    "    'n_estimators': 2000, 'learning_rate': 0.03, 'max_depth': 6,\n",
    "    'subsample': 0.85, 'colsample_bytree': 0.7, 'reg_alpha': 5,\n",
    "    'reg_lambda': 1, 'random_state': 42, 'n_jobs': -1, 'eval_metric': 'auc'\n",
    "}\n",
    "\n",
    "for seed in [42, 123, 777]:\n",
    "    xgb_params['random_state'] = seed\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = XGBClassifier(**xgb_params, early_stopping_rounds=150, verbose=False)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        \n",
    "        oof_xgb[val_idx] += model.predict_proba(X_val)[:, 1] / (skf.n_splits * 3)\n",
    "        test_xgb += model.predict_proba(X_test)[:, 1] / (skf.n_splits * 3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e289e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost CV AUC: 0.726801\n"
     ]
    }
   ],
   "source": [
    "print(f\"XGBoost CV AUC: {roc_auc_score(y, oof_xgb):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22b9c4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1762]\tvalid_0's auc: 0.727363\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1994]\tvalid_0's auc: 0.726088\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1997]\tvalid_0's auc: 0.727262\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1924]\tvalid_0's auc: 0.728042\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1720]\tvalid_0's auc: 0.727912\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's auc: 0.727672\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1998]\tvalid_0's auc: 0.72616\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's auc: 0.727221\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1994]\tvalid_0's auc: 0.728054\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1996]\tvalid_0's auc: 0.728018\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1988]\tvalid_0's auc: 0.727541\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1959]\tvalid_0's auc: 0.72598\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's auc: 0.727304\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1979]\tvalid_0's auc: 0.728129\n",
      "Training until validation scores don't improve for 150 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2000]\tvalid_0's auc: 0.728302\n"
     ]
    }
   ],
   "source": [
    "# 3. LIGHTGBM (3 seeds)\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightgbm as lgb  \n",
    "lgb_params = {\n",
    "    'n_estimators': 2000, 'learning_rate': 0.03, 'max_depth': 6,\n",
    "    'subsample': 0.85, 'colsample_bytree': 0.7, 'reg_alpha': 5,\n",
    "    'reg_lambda': 1, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc',\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "for seed in [42, 123, 777]:\n",
    "    lgb_params['random_state'] = seed\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model = LGBMClassifier(**lgb_params)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_val, y_val)],callbacks=[lgb.early_stopping(150), lgb.log_evaluation(0)])\n",
    "        \n",
    "        oof_lgb[val_idx] += model.predict_proba(X_val)[:, 1] / (skf.n_splits * 3)\n",
    "        test_lgb += model.predict_proba(X_test)[:, 1] / (skf.n_splits * 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e6f898c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM CV AUC: 0.7276152922913872\n"
     ]
    }
   ],
   "source": [
    "print(f\"LightGBM CV AUC: {roc_auc_score(y, oof_lgb):}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0248568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL ENSEMBLE CV ROC-AUC: 0.7269622642381435\n"
     ]
    }
   ],
   "source": [
    "# === WEIGHTED ENSEMBLE (optimized weights) ===\n",
    "# Simple equal weights first, then optimize\n",
    "oof_blend = 0.4 * oof_cat + 0.3 * oof_xgb + 0.3 * oof_lgb\n",
    "test_blend = 0.4 * test_cat + 0.3 * test_xgb + 0.3 * test_lgb\n",
    "\n",
    "final_auc = roc_auc_score(y, oof_blend)\n",
    "print(f\"\\n=== FINAL ENSEMBLE CV ROC-AUC: {final_auc:}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "016315df",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_ids, 'diagnosed_diabetes': test_blend})\n",
    "submission.to_csv('submission.csv', index=False) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
