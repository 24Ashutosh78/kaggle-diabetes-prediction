# kaggle-diabetes-prediction
# Kaggle Diabetes Prediction (Playground Series)

End-to-end machine learning pipeline for diabetes risk prediction using
advanced medical feature engineering, regularized tree ensembles, and
probability calibration. Achieved **Top 15% leaderboard** performance.

## ğŸ† Key Results
- Public Leaderboard AUC: **0.721+**
- Cross-validation AUC: **0.724**
- Kaggle Rank: **Top 15%**
- Best single model: LightGBM (CV AUC: 0.7268)


## ğŸ—ï¸ Pipeline Overview

Raw Data (27 features)  
â†’ 30+ engineered medical & lifestyle features  
â†’ [CatBoost | XGBoost | LightGBM] (5-fold CV)  
â†’ Regularized ensemble (equal weights)  
â†’ Mean-shift probability calibration  
â†’ Final submission (AUC 0.721+)

## ğŸ§ª Modeling Evolution

**Phase 1 â€“ Baseline**
- CatBoost (5-fold CV)
- CV AUC: 0.7238
- Limitation: minimal feature engineering

**Phase 2 â€“ Medical Feature Engineering**
- Lipid ratios (LDL/HDL, TG/HDL)
- Blood pressure metrics
- Lifestyle risk score
- CV â†‘ to 0.7272, but LB drop â†’ overfitting detected

**Phase 3 â€“ Overfit Ensemble**
- 15-model ensemble (multiple seeds)
- Large CVâ€“LB gap (âˆ’0.03)
- OOF mean â‰ˆ 0.63 (expected â‰ˆ 0.15) â†’ severe miscalibration

**Phase 4 â€“ Regularized Ensemble (Final)**
- Reduced depth & model count
- Strong regularization
- CV: 0.724 â†’ LB: 0.721+

**Phase 5 â€“ Probability Calibration**
- Mean-shift calibration using train prevalence
- Stable probabilities & leaderboard consistency

## ğŸ”§ Key Innovations

### Medical Domain Features
- Pulse pressure (vascular risk)
- LDL/HDL ratio (metabolic syndrome marker)
- Lifestyle risk score (sleep, activity, screen time)
- Comorbidity count

### Overfitting Diagnosis
- CVâ€“LB gap analysis
- OOF mean sanity checks

### Production-Ready Calibration
- Mean-shift probability calibration
- Preserves ranking while fixing prevalence bias